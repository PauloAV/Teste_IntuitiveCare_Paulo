# üè• Teste T√©cnico - Engenharia de Dados (ANS)

Este projeto realiza o pipeline de dados (ETL) para extra√ß√£o, transforma√ß√£o e carregamento de Demonstra√ß√µes Cont√°beis das operadoras de planos de sa√∫de, provenientes dos Dados Abertos da ANS.

## üöÄ Funcionalidades

### 1. Extra√ß√£o Autom√°tica (`src/etl/extraction.py`)
- **Automa√ß√£o de Datas:** O script calcula automaticamente a data atual e busca os √∫ltimos 3 trimestres dispon√≠veis, sem necessidade de alterar o c√≥digo manualmente.
- **Margem de Seguran√ßa:** Implementada l√≥gica de "lag" (atraso) de 120 dias para respeitar o calend√°rio de publica√ß√£o da ANS e evitar erros 404.
- **Resili√™ncia:** Tratamento de erros de conex√£o e verifica√ß√£o de integridade dos arquivos ZIP baixados.
- **Organiza√ß√£o:** Os arquivos brutos s√£o salvos automaticamente em `data/raw`.

## üõ†Ô∏è Decis√µes T√©cnicas (Trade-offs)

### Estrat√©gia de Processamento
Optei pelo processamento **em mem√≥ria (In-Memory)** utilizando Pandas, em vez de processamento em stream/chunks.

**Justificativa:**
Ap√≥s an√°lise explorat√≥ria, verificou-se que o volume total dos arquivos CSV trimestrais (aprox. 150MB descompactados) √© significativamente menor que a mem√≥ria RAM dispon√≠vel em ambientes de execu√ß√£o padr√£o (8GB+). A abordagem em mem√≥ria permite:
1. Maior velocidade de desenvolvimento.
2. C√≥digo mais limpo e leg√≠vel.
3. Aproveitamento das otimiza√ß√µes vetoriais do Pandas.

O processamento incremental (streaming) adicionaria complexidade desnecess√°ria para este volume de dados, sendo uma estrat√©gia reservada caso o dataset escalasse para a ordem de Gigabytes.

## üì¶ Como Executar

1. Instale as depend√™ncias:
   ```bash
   pip install -r requirements.txt